---
title: "pog_gen_SNPs_assignment_analyses"
author: "Matthew Bootsma"
date: "April 23, 2019"
output: html_document
---
This analysis is only to asses GSI accuracy as of 4/23/2019

This analysis is based on the scripts used in development and implimentation of GSI+Parentage pipeline in the SNP selection phase of project 1710
    which were derived from Baetscher et al.

This version is what I'm using to produce figures for the GTseq publication
Data is corrected

#dependencies
```{r}
'%!in%' <- function(x,y)!('%in%'(x,y))
library(readxl)
library("reshape2", lib.loc="~/R/win-library/3.5")
# library("tidyverse", lib.loc="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("tictoc", lib.loc="~/R/win-library/3.5")
library(ggplot2)
library(egg)
library("rubias", lib.loc="~/R/win-library/3.5")
#Note:
  #Specific steps were taken to get the CKMRsim package running
  #this involved downloading from Eric's github and removing the 'read_mendel' module from every location 
#e.g. compiler, script, etc.
#This likely disables the ability to produce figure 4 from the paper but we just want to compare figure 3 across data sets
library(CKMRsim)
library(raster)
library(reticulate)
#beepr makes a beep when long sections are done! how fun :)
library(beepr)

```

#-----VCF Processing--------
#Parse
  Parse alleles from raw haps.vcf output produced in stacks_2
```{python}
# script parse haps.vcf file get alleles per individual
# script parse vcf file get alleles per individual
import os
import re
os.getcwd()
os.chdir("I:/WAE_RAD_Data/novoseq2/SNPs/GTseq")
# open vcf file read all lines into an array, close file
raw_vcf_file = open("haps_v2_novoseq2_snps.recode.vcf", "r")
raw_vcf_array = raw_vcf_file.readlines()
raw_vcf_file.close()

# open file you are going to write new results to
out_file = open("haps4rubias_novoseq2.vcf", "w")
r = 1
# for each line in vcf file
a = str(0)
b = str(1)
for i in raw_vcf_array:
    # this is trying to recognize the header line
    if i.startswith("#CHROM"):

        # hard code column names you want
            out_file.write("SNP_ID" + "\t")
            header_line = i.rstrip().split("\t")
            # write individual names
            z = 0
            for j in header_line:
                z = z + 1                
                if z > 9 and z < len(header_line)+1:
                    out_file.write(j + "\t")                 
                #else: out_file.write(j)

            out_file.write("\n")
            # at this point we should have header line

    # use the if not # to go to the data
    elif "#" not in i:
        #write SNP name (allele 1)
        split_SNP_line = i.rstrip().split("\t")
        #print locus CHROM
        out_file.write(split_SNP_line[0] + "\t")
        #Store the locus ID in variable locus_ID
        locus_ID = split_SNP_line[0]
        #Store the haplotype alleles in an array, they will be delimited by ","
        haplotypes = split_SNP_line[3]+","+split_SNP_line[4]
        #immediately break this haplotype allele array into it's components for indexing down the line
        haplotypes = haplotypes.split(",")
        #print(haplotypes)

        # iterates through individual SNP calls
        z = 0
        for j in split_SNP_line:
            #print j

            z = z + 1
            if z > 9 and z < len(header_line)+1:
                # this loop is to make an exception for missing genotypes,
                # which we expect to be "./."
                if j.startswith("."):
                    out_file.write("-"+"\t")
                else:
                    # split the haplotype cell
                    gen_data = j.split(":")
                    #print(gen_data)
                    gen_data = gen_data[0]
                    #print(gen_data)
                    gen_data = gen_data.split("/")
                    #print(gen_data)
                    #gen_data = re.sub('\"','',gen_data)
                    #print(gen_data)
                    # I'm expecting shit to get funky if i call an index directly using the
                    #   value stored in gen_data so I'm going to explicitly assign these to objects
                    index1 = int(gen_data[0])
                    index2 = int(gen_data[1])
                    #print(index1)
                    #print(haplotypes[index1])
                    #use the index stored in the vcf genotype call to index from haplotypes array
                    out_file.write(haplotypes[index1] + "\t")
                    #print gen_data[0]
                    genotype = gen_data[0]
                    #print genotype
                    #the genotype call #/# has a " character attached, this next line removes the "
                    #genotype = re.sub('\"','',genotype)

        out_file.write("\n")
        #print locus CHROM.1 this builds the second allele call for a locus
        out_file.write(split_SNP_line[0]+".1" + "\t")
        z = 0
        for j in split_SNP_line:
            z = z + 1
            if z > 9 and z < len(header_line) + 1:
                # this loop is to make an exception for missing genotypes,
                # which we expect to be "./."
                if j.startswith("."):
                    out_file.write("-" + "\t")
                else:
                    # split the haplotype cell
                    # split the haplotype cell
                    gen_data = j.split(":")
                    #print(gen_data)
                    gen_data = gen_data[0]
                    #print(gen_data)
                    gen_data = gen_data.split("/")
                    #print(gen_data)
                    # I'm expecting shit to get funky if i call an index directly using the
                    #   value stored in gen_data so I'm going to explicitly assign these to objects
                    index1 = int(gen_data[0])
                    index2 = int(gen_data[1])
                    # use the index stored in the vcf genotype call to index from haplotypes array
                    out_file.write(haplotypes[index2] + "\t")
                    # print gen_data[0]
                    genotype = gen_data[0]
                    # print genotype
                    # the genotype call #/# has a " character attached, this next line removes the "
                    # genotype = re.sub('\"','',genotype)
        #at this point both alleles should be processed. add a new line for the next locus iteration
        out_file.write("\n")
        

out_file.close()  # script parse vcf file get alleles per individual

```
#Transpose
  Transpose allele information produced in the python parse script
  Build BASE WAE data set with all samples
```{r}
#Read in the parsed vcf and transpose, we're going to 
vcf_input = read.delim("../../haps4rubias_novoseq2.vcf",sep="\t",header=TRUE, na.strings = c("-","."))
transposed_data1 = as.data.frame(as.matrix(t(vcf_input)))
#
#remove raw vcf array and allocate naming vectors to build the base of the final rubias dataset
rm(vcf_input)
WAE_base = as.data.frame(matrix(NA,
                                nrow = nrow(transposed_data1)-1,
                                ncol = ncol(transposed_data1)+4))
Hsub = t(as.vector(transposed_data1[1,1:ncol(transposed_data1)]))
#
#build base of final rubias dataset, bringing names from parsed vcf
for (i in 1:ncol(WAE_base)) {
  if (i == 1) {
    colnames(WAE_base)[i] = 'sample_type'
  }
  else if (i == 2) {
    colnames(WAE_base)[i] = 'repunit'
  }
  else if (i == 3) {
    colnames(WAE_base)[i] = 'collection'
  }
  else if (i == 4) {
    colnames(WAE_base)[i] = 'indiv'
  }
  else
    colnames(WAE_base)[i] = Hsub[i-4,1]
}
rm(Hsub)
#
#write the transposed file out and read it back in due to poor R df manipulation skills
write.csv(transposed_data1, "./transposed_hap_alleles_4_rubias.csv")
rm(transposed_data1)
transposed_data2 = read.csv("./transposed_hap_alleles_4_rubias.csv", sep = ",")
#
#bring the transposed data into the base rubias dataset
head(transposed_data2)
WAE_base[,4:ncol(WAE_base)] = transposed_data2[2:nrow(transposed_data2),1:ncol(transposed_data2)]
rm(transposed_data2)
WAE_base = WAE_base[-nrow(WAE_base),]
#
#add collection info to base dataset, type cast col 1:4 as characters
metaData_collection= gsub("\\d+", "", WAE_base$indiv)
WAE_base$collection = as.character(metaData_collection)
rm(metaData_collection)
WAE_base$indiv = as.character(WAE_base$indiv)
write.csv(WAE_base,"./rubias_hap_allele_data.csv")
head(WAE_base)
beep()
```

#----POST VCF Processing---

#Define Reporting Units
  training and holdout requires just that. We're going to split samples 50/50 assigning every other one to reference/mixture groups
  this section will also define reporting units for 1710_WAE data specifically
```{r}
#read in data EVEN IF you've already done the conversion from .vcf
WAE_base = read.csv("./rubias_hap_allele_data.csv", colClasses = c("character"), row.names = NULL)
WAE_base[,sapply(WAE_base,class) == "logical"] <-
  sapply(WAE_base[,sapply(WAE_base,class) == "logical"],
         function(i) substr(as.character(i),1,1))
WAE_base = WAE_base[,-1]

WAE_base$repunit = as.character(WAE_base$repunit)
for (i in 1:nrow(WAE_base)) {
  
  if(WAE_base[i,3] == "Lake_Wisconsin.."|
     WAE_base[i,3]== "Big_Arbor_Vitae.."|
     WAE_base[i,3]== "Kawaguesaga.."|
     WAE_base[i,3]== "Medicine_Lake.."|
     WAE_base[i,3]== "Willow_Flowage.."){
    
    WAE_base[i,2] = "Rep_U-Wisconsin"
  }
  
  else if(WAE_base[i,3] == "Chippewa_Flowage.."|
          WAE_base[i,3]== "Eau_Claire_River.."|
          WAE_base[i,3]== "Lake_Millicent.."|
          WAE_base[i,3]== "Manitowish_Lake.."|
          WAE_base[i,3]== "Turtle_Flambeau_Flowage.."|
          WAE_base[i,3]== "Sanford_Lake.."|
          WAE_base[i,3]== "Escanaba_Lake.."|
          WAE_base[i,3]== "Escanaba.."
          ){
    
    WAE_base[i,2] = "Rep_U-Chippewa"
  }
  
  else if(WAE_base[i,3] == "Cutfoot_Sioux.."){
    WAE_base[i,2] = "Rep_U-Cutfoot_Sioux"
  }
  else if(WAE_base[i,3]== "Lake_Koronis.."){
    WAE_base[i,2] = "Rep_U-Lake_Koronis"
  }
  else if(WAE_base[i,3]== "Mille_Lacs.."){
    WAE_base[i,2] = "Rep_U-Mille_Lacs"
  }
  else if(WAE_base[i,3]== "Ottertail_Lake.."){
    WAE_base[i,2] = "Rep_U-Ottertail_Lake"
  }
  else if(WAE_base[i,3]== "Pike_River.."){
    WAE_base[i,2] = "Rep_U-Pike_River"
  }
  else if(WAE_base[i,3]== "Pine_River.."){
    WAE_base[i,2] = "Rep_U-Pine_River"
  }
  else if(WAE_base[i,3]== "Red_Lake.."){
    WAE_base[i,2] = "Rep_U-Red_Lake"
  }
  else if(WAE_base[i,3]== "Sarah_Lake.."){
    WAE_base[i,2] = "Rep_U-Sarah_Lake"
  }
  else if(WAE_base[i,3] == "Delavan.."){
    WAE_base[i,2] = "Rep_U-Delavan"
  }
  else if(WAE_base[i,3] == "WolfR_."){
    WAE_base[i,2] = "Rep_U-Wolf_River"
  }
  else if(WAE_base[i,3] == "St_Louis_River.."){
    WAE_base[i,2] = "Rep_U-St_Louis"
  }
  else{
    WAE_base[i,2] = "Rep_U-Other"
  }
}

WAE_base$repunit = as.factor(WAE_base$repunit)
head(WAE_base)
beep()
WAE_base[which(WAE_base$repunit == "Rep_U-Other"),]

for (i in unique(WAE_base$repunit)) {
  print(i)
  print(length(which(WAE_base$repunit == i)))
}
WAE_base[which(WAE_base$repunit == "Rep_U-Lake_Koronis"),]

WAE_base[which(WAE_base$collection == "Escanaba_Lake.."),"collection"] = "Escanaba.."
```
#SELECT SNPS HERE

  MAKE SURE QUALITY TABLE CORRESPONDS DIRECTLY TO DATA, ONE SNP DIFFERENCE WILL PRODUCE ERRORS IN INDEXING!!!!
  
```{r}
test_seq = seq(5,27936, by = 2)
rubias_index = c(1,2,3,4,test_seq[which(unique(selection_dat$CHROM) %in% loci_for_panel)],test_seq[which(unique(selection_dat$CHROM) %in% loci_for_panel)]+1)
rubias_index = sort(rubias_index)

```

#Define reference and mixture

  NO FAKE POPS IN REFERENCE
```{r}
natural_WAE = WAE_base[which(WAE_base$collection %!in% c("Lake_Millicent..","Sanford_Lake..","Escanaba..","Escanaba_Lake..")),rubias_index]
# natural_WAE = WAE_base[which(WAE_base$collection %!in% c("Lake_Millicent..","Sanford_Lake..","Escanaba..")),]

# NOTE: for odd number of samples, use line 279 in place of line 278
# natural_WAE$sample_type = c(rep(c("reference","mixture"),nrow(natural_WAE)/2))
# natural_WAE$sample_type = c(rep(c("reference","mixture"),nrow(natural_WAE)/2),"reference")
# 
# head(natural_WAE)

#if you have samples you don't want in the training but do want in the holdout, put them here
# fake_WAE = WAE_base[which(WAE_base$collection %in% c("Lake_Millicent..","Sanford_Lake..","Escanaba..")),]
# fake_WAE$sample_type = "mixture"

# repU_defined_WAE = rbind.data.frame(
#   natural_WAE)  #, fake_WAE)
#subsetting the known collection data so we can easily subset correct vs incorrect assignments post mixture analysis
# known_collection_meta_dat = repU_defined_WAE$collection
# known_repU_meta_dat = repU_defined_WAE$repunit
# repU_defined_WAE = cbind.data.frame(known_collection_meta_dat,known_repU_meta_dat,repU_defined_WAE)
# 
# repU_defined_WAE$repunit = as.character(repU_defined_WAE$repunit)
# 
# repU_defined_WAE[which(repU_defined_WAE$sample_type == "mixture"),"repunit"] = NA
# repU_defined_WAE[which(repU_defined_WAE$sample_type == "mixture"),"collection"] = "Mixed_collection"
# 
# repU_defined_WAE[] = lapply(repU_defined_WAE, as.character)
# save(repU_defined_WAE,file = "./rubias_hap_training_and_holdout_data.rda")
# save(known_collection_meta_dat, file =  "./rubias_hap_results_collection_metadata.rda")
# save(known_repU_meta_dat, file =  "./rubias_hap_results_reporting_unit_metadata.rda")
beep()
```

#------Simulations------
# 100% Simulations 
this section is dependent upon the object called LOO_in, which was built for the LOO sims. 
it is just a subset of rubias formatted data, based on the indeces of the panel you are currently testing

```{r}
# LOO_in = WAE_base[,rubias_index]
LOO_in = natural_WAE
# LOO_in = WAE_base
#call all samples reference for 10% SIM
LOO_in$sample_type = "reference"
#make data all character type 
LOO_in[] = lapply(LOO_in, as.character)
head(LOO_in)

#Builds specific folder for each panel's results
# dir.create(paste("./results/Panel_tests/",panel_name,sep = ""))
#saves the panel subset as an .Rda to load and look at later
# save(index_temp, file = paste("./data/panel_analyses/panel-",panel_name,".Rda", sep = ""))
```

ALWAYS CHECK STARTING COLUMN!!!!
## Simulate by REPU
```{r}
#by repU
# make a list of data frames with the proportions
six_hundy_scenarios <- lapply(unique(LOO_in$repunit), function(x) tibble(repunit = x, ppn = 1.0))
# give it some names too:
names(six_hundy_scenarios) <- paste("All", unique(LOO_in$repunit), sep = "-")

repu_hundy_results <- assess_reference_loo(reference = LOO_in,
                     gen_start_col = 5,
                     reps = 1000,
                     mixsize = 200,
                     seed = 5,
                     alpha_repunit = six_hundy_scenarios,
                     alpha_collection = 10,
                     return_indiv_posteriors = TRUE,
                     #seed = 5
                     )
#                      
beep()
save(repu_hundy_results, file = paste("./REPU_hundy_sim_results",panel_name,".rda",sep = ""))
#For some reasone the simulations were filling the simulation repunit and collection metadata with NA's after the first simulation
#this is some janky ass hardcoding to fix the problem for me. If you can generalize it great! Let me know what you did plz ;)
#or if you want to think less... just replace 20 with the number of collections you have in your data :D
simU_id = repu_hundy_results$mixing_proportions$repunit[1:20]
sim_collect_ids = repu_hundy_results$mixing_proportions$collection[1:20]
#this puts the metadata back into the results
repu_hundy_results$mixing_proportions$repunit = simU_id
repu_hundy_results$mixing_proportions$collection = sim_collect_ids

#calculate the net simulated mle_pi for each reporting unit, by iteration, for each 100% collection
hundy_sim_summary = repu_hundy_results$mixing_proportions %>% 
  group_by(repunit_scenario, iter, repunit) %>% 
  summarise(net_pi_mle_by_repu = round(sum(mle_pi),2)) %>% 
  ungroup()
#calculate an average simulated mle_pi for each reporting unit, over all iterations, for each 100% collection
hundy_sim_summary_mean_pi_mle = hundy_sim_summary %>% 
  group_by(repunit_scenario, repunit) %>% 
  summarise(avg_pi_mle_by_repu = mean(net_pi_mle_by_repu))
#calculate 95%CI around the mean
hundy_sim_summary_95CI = hundy_sim_summary %>% 
  group_by(repunit_scenario, repunit) %>% 
  summarise(CI95_pi_mle_by_repu = (1.96*(sd(net_pi_mle_by_repu)/sqrt(length(net_pi_mle_by_repu)))))
```




## Simulate by POP

#SELECT SNPS HERE for just POP sim

  MAKE SURE QUALITY TABLE CORRESPONDS DIRECTLY TO DATA, ONE SNP DIFFERENCE WILL PRODUCE ERRORS IN INDEXING!!!!
  
```{r}
test_seq = seq(5,27936, by = 2)
rubias_index = c(1,2,3,4,test_seq[which(unique(selection_dat$CHROM) %in% loci_for_panel)],test_seq[which(unique(selection_dat$CHROM) %in% loci_for_panel)]+1)
rubias_index = sort(rubias_index)

natural_WAE = WAE_base[which(WAE_base$collection %!in% c("Lake_Millicent..","Sanford_Lake..","Escanaba..","Escanaba_Lake..")),rubias_index]

# LOO_in = WAE_base[,rubias_index]
LOO_in = natural_WAE
# LOO_in = WAE_base
#call all samples reference for 10% SIM
LOO_in$sample_type = "reference"
#make data all character type 
LOO_in[] = lapply(LOO_in, as.character)
head(LOO_in)


```

```{r}
hundy_colls = unique(LOO_in$collection)

hundy_coll_list <- lapply(hundy_colls, function(x) tibble(collection = x, ppn = 1.0)) %>%
  setNames(paste("100%", hundy_colls, sep = "_"))


#run sim, MAKE SURE TO SPECIFY THE CORRECT ALPHA
repu_hundy_results <- assess_reference_loo(reference = LOO_in, 
                     gen_start_col = 5, 
                     reps = 1000,
                     mixsize = 200,
                     # reps = 10, 
                     # mixsize = 200,
                     seed = 5,
                     alpha_collection = hundy_coll_list,
                     return_indiv_posteriors = TRUE,
                     #seed = 5
                     )
beep()

save(repu_hundy_results, file = paste("./POP_hundy_sim_results",panel_name,".rda",sep = ""))
```
# POP
```{r}
panel_name = "FST_600"

load(paste("./",panel_name,"/POP_hundy_sim_results",panel_name,".rda", sep = ""))
POP_sim_result = repu_hundy_results$indiv_posteriors
rm(repu_hundy_results)
```

```{r}
test_report = POP_sim_result %>% 
  group_by(collection_scenario, iter, indiv) %>% 
  filter(PofZ == max(PofZ))
```

```{r}
test_report2 = test_report %>% 
  group_by(simulated_collection,collection) %>% 
  summarise(
    prop_assigned = length(which(PofZ>0.7))/200000, 
    n_unassigned = length(which(PofZ<0.7)), 
    nsims = length(PofZ)
  )

whitelistXY = read.csv("./sim_XY_whitelist.csv")


test_report2$simed_from_Ycoord = NA
test_report2$assigned_to_Xcoord = NA

for (i in 1:nrow(whitelistXY)) {
    test_report2[which(test_report2$simulated_collection == whitelistXY[i,"Pop"]),"simed_from_Ycoord"] = whitelistXY[i,"XY_pop"]
    test_report2[which(test_report2$collection == whitelistXY[i,"Pop"]),"assigned_to_Xcoord"] = whitelistXY[i,"XY_pop"]
}


write.csv(test_report2,file = paste("./",panel_name,"/POP_sim_to_plot_",panel_name,".csv", sep = ""), row.names = F)
```

```{r}
test_report2[which(test_report2$prop_assigned < 0.01),"simed_from_Ycoord"] = NA
dat_2_plot = test_report2

ggplot(dat_2_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = prop_assigned))+
  geom_point(shape = 21, fill = "gray", color = "black", 
             alpha = 0.5, inherit.aes = T, 
             size = (18*dat_2_plot$prop_assigned))+
  geom_text(aes(label=round(prop_assigned*100,0)), 
            size = 8)+
  #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
  scale_x_continuous(
    breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
    labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
    )+
  #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
  scale_y_continuous(
    breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
    labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
                       )+
  labs(x = "Assigned Population", y = "Simulated Population")+
  theme(
    plot.title = element_text(hjust = 0.5, size = 28),
    axis.title = element_text(size = 22),
    axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
    axis.text.y = element_text(size = 16),
    panel.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(colour = "#666666"),
    panel.border = element_rect(colour = "#666666", fill=NA, size=1),
    legend.position = "none"
  )+
  geom_hline(yintercept = c(2.5,7.5,13.5))+
  geom_vline(xintercept = c(2.5,7.5,13.5))+
  ggsave(filename = paste("./",panel_name,"/POP_", panel_name, ".jpg", sep = ""), width = 11.5, height = 11.5, dpi = 350)
```


# REPU
```{r}
load(paste("./",panel_name,"/REPU_hundy_sim_results",panel_name,".rda", sep = ""))
POP_sim_result = repu_hundy_results$indiv_posteriors
rm(repu_hundy_results)
```

```{r}
test_report = POP_sim_result %>% 
  group_by(repunit_scenario, iter, indiv) %>% 
  filter(PofZ == max(PofZ))
```

```{r}
test_report2 = test_report %>% 
  group_by(simulated_repunit,repunit) %>% 
  summarise(
    prop_assigned = length(which(PofZ>0.7))/200000, 
    n_unassigned = length(which(PofZ<0.7)), 
    nsims = length(PofZ)
  )

whitelistXY = read.csv("./sim_XY_whitelist.csv")


test_report2$simed_from_Ycoord = NA
test_report2$assigned_to_Xcoord = NA

for (i in 1:nrow(whitelistXY)) {
    test_report2[which(test_report2$simulated_repunit == whitelistXY[i,"REPU"]),"simed_from_Ycoord"] = whitelistXY[i,"XY_repu"]
    test_report2[which(test_report2$repunit == whitelistXY[i,"REPU"]),"assigned_to_Xcoord"] = whitelistXY[i,"XY_repu"]
}


write.csv(test_report2,file = paste("./",panel_name,"/REPU_sim_to_plot_",panel_name,".csv", sep = ""), row.names = F)
```

```{r}
test_report2[which(test_report2$prop_assigned < 0.01),"simed_from_Ycoord"] = NA
ggplot(test_report2, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = prop_assigned))+
  geom_point(shape = 21, fill = "gray", color = "black", 
             alpha = 0.5, inherit.aes = T, 
             size = (18*test_report2$prop_assigned))+
  geom_text(aes(label=round(prop_assigned*100,0)), 
            size = 8)+
  #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
  scale_x_continuous(
    breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
    labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
    )+
  #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
  scale_y_continuous(    
    breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
    labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
                       )+
  labs(x = "Assigned Reporting Unit", y = "Simulated Reporting Unit")+
  theme(
    plot.title = element_text(hjust = 0.5, size = 28),
    axis.title = element_text(size = 22),
    axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
    axis.text.y = element_text(size = 16),
    panel.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(colour = "#666666"),
    panel.border = element_rect(colour = "#666666", fill=NA, size=1),
    legend.position = "none"
  )+
  geom_hline(yintercept = 4.5)+
  geom_vline(xintercept = 4.5)+
  ggsave(filename = paste("./",panel_name,"/REPU_", panel_name, ".jpg", sep = ""), width = 11.5, height = 11.5, dpi = 350)
```


##----- IN TESTING, HARDCODING PRESENT IN SIMULATION SUMMARY FUNCTIONS
# Look at accuracy by sim type

  By POP
```{r}
result_summary_POP = read.csv("./mhapHE_600/POP_sim_to_plot_mhapHE_600.csv")
# Self assignment results
result_summary_POP[which(result_summary_POP$simulated_collection == result_summary_POP$collection),]
# prop unassigned by repu
result_summary_POP %>% 
  group_by(simulated_collection) %>% 
  summarise(sum(n_unassigned)/200000)
# average accuracy by repu
mean(result_summary_POP[which(result_summary_POP$simulated_collection == result_summary_POP$collection),"prop_assigned"])

result_summary_REPU = read.csv(file = paste("./",panel_name,"/REPU_sim_to_plot_", panel_name, ".csv", sep = ""))

# prop unassigned by repu
result_summary_REPU %>% 
  group_by(simulated_repunit) %>% 
  summarise(sum(n_unassigned)/200000)
# average accuracy by repu
mean(result_summary_REPU[which(result_summary_REPU$simulated_repunit == result_summary_REPU$repunit),"prop_assigned"])
```
  By REPU
```{r}
# result_summary_REPU = read.csv("./Composite_600/REPU_sim_to_plot_Composite_600.csv")
# result_summary_REPU = read.csv("./FST_600/REPU_sim_to_plot_FST_600.csv")
result_summary_REPU = read.csv("./mhapHE_600/REPU_sim_to_plot_mhapHE_600.csv")
# Self assignment results
result_summary_REPU[which(result_summary_REPU$simulated_repunit == result_summary_REPU$repunit),1:3]
# prop unassigned by repu
# result_summary_REPU %>% 
#   group_by(simulated_repunit) %>% 
#   summarise(sum(n_unassigned)/200000)
# # average accuracy by repu
# mean(result_summary_REPU[which(result_summary_REPU$simulated_repunit == result_summary_REPU$repunit),"prop_assigned"])
# 
# result_summary_REPU = read.csv(file = paste("./",panel_name,"/REPU_sim_to_plot_", panel_name, ".csv", sep = ""))
# 
# # prop unassigned by repu
# result_summary_REPU %>% 
#   group_by(simulated_repunit) %>% 
#   summarise(sum(n_unassigned)/200000)
# # average accuracy by repu
# mean(result_summary_REPU[which(result_summary_REPU$simulated_repunit == result_summary_REPU$repunit),"prop_assigned"])
```

# Looking an n_unassigned by panel
```{r}
panel_ID = "Composite_600"
# unassigned_calc = read.csv("./Composite_600/REPU_sim_to_plot_Composite_600.csv")
unassigned_calc = read.csv(paste("./",panel_ID,"/REPU_sim_to_plot_",panel_ID,".csv", sep = "")) %>% 
  group_by(simulated_repunit) %>% 
  summarise(prop_unassigned = sum(n_unassigned)/sum(nsims))
unassigned_calc$panel = panel_ID
unassigned_calc$Reporting_Unit = gsub("Rep_U-","",unassigned_calc$simulated_repunit)
# ggplot(tmp_calc)+
#   geom_boxplot(aes(y = prop_unassigned))
```


##Box/violin Plots by repu

```{r}
panel_ID = "mhapHE_600"
load(paste("./",panel_ID,"/REPU_hundy_sim_results",panel_ID,".rda", sep = ""))
# result_summary_REPU = read.csv("./Composite_600/REPU_sim_to_plot_Composite_600.csv")
# result_summary_REPU = read.csv("./FST_600/REPU_sim_to_plot_FST_600.csv")

result_2plot_REPU = repu_hundy_results$indiv_posteriors

result_2plot_REPU2 = result_2plot_REPU %>% 
  group_by(repunit_scenario,iter,indiv) %>% 
  filter(PofZ == max(PofZ)) %>% 
  group_by(collection_scenario, iter, simulated_repunit) %>% 
  summarise(accuracy = length(which(simulated_repunit == repunit & PofZ > 0.7))/200, 
            prop_unassigned = length(which(PofZ < 0.7))/200)

# Calculate point accuracy, no variance
# result_2plot_REPU2 = result_2plot_REPU %>% 
#   group_by(repunit_scenario,iter,indiv) %>% 
#   filter(PofZ > 0.7 & PofZ == max(PofZ) & simulated_repunit == repunit) %>% 
#   group_by(repunit_scenario) %>% 
#   summarise(accuracy = length(which(simulated_repunit == repunit))/200000)

result_2plot_REPU2$panel = panel_ID
result_2plot_REPU2$Reporting_Unit = gsub("Rep_U-","",result_2plot_REPU2$simulated_repunit)

#join data frames
# merged_results_2plot_REPU = result_2plot_REPU2
merged_results_2plot_REPU = rbind.data.frame(merged_results_2plot_REPU,result_2plot_REPU2)
unique(merged_results_2plot_REPU$panel)

# means_dat = merged_results_2plot_REPU

# save(merged_results_2plot_REPU, file =  "./merged_sim_results_2plot.rda")
load("./merged_sim_results_2plot.rda")
```

```{r}
unique(merged_results_2plot_REPU$Reporting_Unit)
merged_results_2plot_REPU$Reporting_Unit = factor(merged_results_2plot_REPU$Reporting_Unit, levels = c("Delavan","Wolf_River","Wisconsin","Chippewa","St_Louis","Pike_River","Sarah_Lake","Lake_Koronis","Mille_Lacs","Pine_River","Cutfoot_Sioux","Ottertail_Lake","Red_Lake"))

unique(merged_results_2plot_REPU$panel)
merged_results_2plot_REPU$panel = factor(merged_results_2plot_REPU$panel, levels =c("FST_600","Composite_600","mhapHE_600"))
```


```{r}
library(ggplot2)
dodge = position_dodge(width = 1)
ggplot(merged_results_2plot_REPU, 

       )+
  geom_violin(position = dodge,
              scale = "width", 
              # fill= "white",
              fill= "#CCFFCC",
              alpha = 0.6,
              # draw_quantiles = c(0.25, 0.5, 0.75),
              aes(
                x = Reporting_Unit,
                y = accuracy, 
                color = panel
                )
              )+
  geom_boxplot(position = dodge,width=.05, outlier.colour = NA,
               aes(
                x = Reporting_Unit,
                y = accuracy, 
                # fill= panel,
                color = panel
                )
               )+
  scale_color_manual(values = c("#FF0000","#000000","#9900FF"), name = "Panel ID")+
  geom_violin(position = dodge,
              scale = "width", 
              fill = "grey80",
              linetype = "dotted",
              aes(
                x = Reporting_Unit,
                y = prop_unassigned, 
                # fill= panel,
                color = panel,
                )
              )+
    geom_boxplot(position = dodge,width=.05, outlier.colour = NA,
               aes(
                x = Reporting_Unit,
                y = prop_unassigned, 
                # fill= panel,
                color = panel
                )
               )+
  # scale_color_manual(values = c("#000000","#000000","#9900FF"), name = "Panel ID")+
  
  ylim(0,1)+
  # stat_summary(fun.y="median", geom="point")
  theme(axis.title = element_text(face = "bold", size = 22),
        axis.text.x = element_text(angle = 90, hjust = 1),
        axis.text = element_text(face="bold", size = 18),
        legend.text = element_text(face="bold", size = 18),
        # legend.position = c(0.98,0.25),
        # legend.justification = c(1,-0.2),
        legend.position = "bottom",
        panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  
  geom_vline(xintercept = c(1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5,10.5,11.5,12.5), 
             linetype = "twodash", 
             alpha = 0.3
             )+
  labs(x = "Reporting Unit", y = "Proportion\n")

ggsave("./test2merge_results_violin_plot.jpg", width = 18, height = 9, units = "in", dpi = 350)
```

# Look at results by simulation scenario
```{r}
merged_results_2plot_REPU %>% 
  group_by(simulated_repunit) %>% 
  summarize(mean(accuracy), min(accuracy), max(accuracy))
  
merged_results_2plot_REPU %>% 
  group_by(panel) %>% 
  summarize(mean(accuracy), mean(prop_unassigned))
```

##------ NOT TESTED

# Build 3 panel plot
 By REPU
```{r}
# load("./simulation_result_FST_600byREPU.rda")
# FST_plot = summarize_indv_assignment_melted
# 
# p_FST = ggplot(FST_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = proportion))+
#   geom_point(shape = 21, fill = "gray", color = "black",
#              alpha = 0.5, inherit.aes = T,
#              size = (18*FST_plot$proportion))+
#   geom_text(aes(label=round(proportion*100,0)),
#             size = 8)+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_x_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
#     labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_y_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
#     labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#                        )+
#   labs(x = " ", y = "Simulated Reporting Unit", title = "FST 600")+
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 28),
#     axis.title = element_text(size = 22),
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
#     axis.text.y = element_text(size = 16),
#     panel.background = element_blank(),
#     panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     axis.line = element_line(colour = "#666666"),
#     panel.border = element_rect(colour = "#666666", fill=NA, size=1),
#     legend.position = "none"
#   )
#   # geom_hline(yintercept = 4.5)
# 
# load("./simulation_result_composite_600byREPU.rda")
# composite_plot = summarize_indv_assignment_melted
# 
# p_composite = ggplot(composite_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = proportion))+
#   geom_point(shape = 21, fill = "gray", color = "black",
#              alpha = 0.5, inherit.aes = T,
#              size = (18*composite_plot$proportion))+
#   geom_text(aes(label=round(proportion*100,0)),
#             size = 8)+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_x_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
#     labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_y_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
#     labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#                        )+
#   labs(x = "Assigned Reporting Unit", y = NULL, title = "Composite 600")+
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 28),
#     axis.title = element_text(size = 22),
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
#     axis.text.y = element_text(size = 16),
#     panel.background = element_blank(),
#     panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     axis.line = element_line(colour = "#666666"),
#     panel.border = element_rect(colour = "#666666", fill=NA, size=1),
#     legend.position = "none"
#   )
#   # geom_hline(yintercept = 4.5)
# 
# load("./simulation_result_mhapHE_600byREPU.rda")
# HE_plot = summarize_indv_assignment_melted
# 
# p_HE = ggplot(HE_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = proportion))+
#   geom_point(shape = 21, fill = "gray", color = "black",
#              alpha = 0.5, inherit.aes = T,
#              size = (18*HE_plot$proportion))+
#   geom_text(aes(label=round(proportion*100,0)),
#             size = 8)+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_x_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
#     labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_y_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13),
#     labels = c('Delavan', 'Wolf River', 'Wisconsin', 'Chippewa', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#                        )+
#   labs(x = " ", y = NULL, title = "mhap_He 600")+
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 28),
#     axis.title = element_text(size = 22),
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
#     axis.text.y = element_text(size = 16),
#     panel.background = element_blank(),
#     panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     axis.line = element_line(colour = "#666666"),
#     panel.border = element_rect(colour = "#666666", fill=NA, size=1),
#     legend.position = "none"
#   )
#   # geom_hline(yintercept = 4.5)
# 
# ggsave(grid.arrange(p_FST,p_composite,p_HE, nrow = 1),width = 34, height = 11.5, filename = "./TEST_triplot_byREPU.jpg")
```

Accuracy measures by repU
By panel on average
```{r}
# mean(FST_plot[which(FST_plot$assigned_to_Xcoord == FST_plot$simed_from_Ycoord & !is.na(FST_plot$proportion)),"proportion"])
# #
# mean(composite_plot[which(composite_plot$assigned_to_Xcoord == composite_plot$simed_from_Ycoord & !is.na(composite_plot$proportion)),"proportion"])
# #
# mean(HE_plot[which(HE_plot$assigned_to_Xcoord == HE_plot$simed_from_Ycoord & !is.na(HE_plot$proportion)),"proportion"])


```

By repU
```{r}
# FST_plot
# self_assignments_FST = FST_plot[which(FST_plot$simed_from_Ycoord == FST_plot$assigned_to_Xcoord),]
# self_assignments_FST$panel = "FST_600"
# self_assignments_FST2 = self_assignments_FST[,c("panel","simulated_from","proportion")]
# 
# composite_plot
# self_assignments_composite = composite_plot[which(composite_plot$simed_from_Ycoord == composite_plot$assigned_to_Xcoord),]
# self_assignments_composite$panel = "composite_600"
# self_assignments_composite2 = self_assignments_composite[,c("panel","simulated_from","proportion")]
# 
# 
# HE_plot
# self_assignments_HE = HE_plot[which(HE_plot$simed_from_Ycoord == HE_plot$assigned_to_Xcoord),]
# self_assignments_HE$panel = "HE_600"
# self_assignments_HE2 = self_assignments_HE[,c("panel","simulated_from","proportion")]
# 
# self_assignements_summary = rbind.data.frame(self_assignments_FST2,self_assignments_composite2,self_assignments_HE2)
# 
# write.csv(self_assignements_summary, file = "./summary_hundySim_by_POP.csv", row.names = F, quote = F)

```

By POP
```{r}
# load("./simulation_result_FST_600_byPOP.rda")
# FST_plot = summarize_indv_assignment_melted
# 
# p_FST = ggplot(FST_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = proportion))+
#   geom_point(shape = 21, fill = "gray", color = "black",
#              alpha = 0.5, inherit.aes = T,
#              size = (18*FST_plot$proportion))+
#   geom_text(aes(label=round(proportion*100,0)),
#             size = 8)+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_x_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
#     labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_y_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
#     labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   labs(x = " ", y = "Simulated Reporting Unit", title = "FST 600")+
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 28),
#     axis.title = element_text(size = 22),
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
#     axis.text.y = element_text(size = 16),
#     panel.background = element_blank(),
#     panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     axis.line = element_line(colour = "#666666"),
#     panel.border = element_rect(colour = "#666666", fill=NA, size=1),
#     legend.position = "none"
#   )
#   # geom_hline(yintercept = 4.5)
# 
# load("./simulation_result_composite_600_byPOP.rda")
# composite_plot = summarize_indv_assignment_melted
# 
# p_composite = ggplot(composite_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = proportion))+
#   geom_point(shape = 21, fill = "gray", color = "black",
#              alpha = 0.5, inherit.aes = T,
#              size = (18*composite_plot$proportion))+
#   geom_text(aes(label=round(proportion*100,0)),
#             size = 8)+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_x_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
#     labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_y_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
#     labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   labs(x = "Assigned Reporting Unit", y = NULL, title = "Composite 600")+
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 28),
#     axis.title = element_text(size = 22),
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
#     axis.text.y = element_text(size = 16),
#     panel.background = element_blank(),
#     panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     axis.line = element_line(colour = "#666666"),
#     panel.border = element_rect(colour = "#666666", fill=NA, size=1),
#     legend.position = "none"
#   )
#   # geom_hline(yintercept = 4.5)
# 
# load("./simulation_result_mhapHE_600_byPOP.rda")
# HE_plot = summarize_indv_assignment_melted
# 
# p_HE = ggplot(HE_plot, aes(x = assigned_to_Xcoord, y = simed_from_Ycoord, size = proportion))+
#   geom_point(shape = 21, fill = "gray", color = "black",
#              alpha = 0.5, inherit.aes = T,
#              size = (18*HE_plot$proportion))+
#   geom_text(aes(label=round(proportion*100,0)),
#             size = 8)+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_x_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
#     labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   #DID YOU CODE THE XY VALUES CORRECTLY ABOVE? SEE auto_axis_list
#   scale_y_continuous(
#     breaks = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
#     labels = c('Delavan', 'Wolf River', 'Lake Wisconsin', 'Medicine Lake', 'Willow Flowage', 'Kawaguesaga', 'Big Arbor Vitae', 'Manitowish Lake', 'Turtle Flambeau', 'Chippewa Flowage', 'Eau Claire River', 'St Louis', 'Pike River', 'Sarah Lake', 'Lake Koronis', 'Mille Lacs', 'Pine River', 'Cutfoot Sioux', 'Ottertail Lake', 'Red Lake')
#     )+
#   labs(x = " ", y = NULL, title = "mhap_He 600")+
#   theme(
#     plot.title = element_text(hjust = 0.5, size = 28),
#     axis.title = element_text(size = 22),
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 16),
#     axis.text.y = element_text(size = 16),
#     panel.background = element_blank(),
#     panel.grid.major = element_blank(),
#     panel.grid.minor = element_blank(),
#     axis.line = element_line(colour = "#666666"),
#     panel.border = element_rect(colour = "#666666", fill=NA, size=1),
#     legend.position = "none"
#   )
#   # geom_hline(yintercept = 4.5)
# 
# ggsave(grid.arrange(p_FST,p_composite,p_HE, nrow = 1),width = 34, height = 11.5, filename = "./TEST_triplot_byPOP.jpg")
```

Accuracy measures by POP

average by panel
```{r}
# mean(FST_plot[which(FST_plot$assigned_to_Xcoord == FST_plot$simed_from_Ycoord & !is.na(FST_plot$proportion)),"proportion"])
# #
# mean(composite_plot[which(composite_plot$assigned_to_Xcoord == composite_plot$simed_from_Ycoord & !is.na(composite_plot$proportion)),"proportion"])
# #
# mean(HE_plot[which(HE_plot$assigned_to_Xcoord == HE_plot$simed_from_Ycoord & !is.na(HE_plot$proportion)),"proportion"])


```

By pop
```{r}
# FST_plot
# self_assignments_FST = FST_plot[which(FST_plot$simed_from_Ycoord == FST_plot$assigned_to_Xcoord),]
# self_assignments_FST$panel = "FST_600"
# self_assignments_FST2 = self_assignments_FST[,c("panel","simulated_from","proportion")]
# 
# composite_plot
# self_assignments_composite = composite_plot[which(composite_plot$simed_from_Ycoord == composite_plot$assigned_to_Xcoord),]
# self_assignments_composite$panel = "composite_600"
# self_assignments_composite2 = self_assignments_composite[,c("panel","simulated_from","proportion")]
# 
# 
# HE_plot
# self_assignments_HE = HE_plot[which(HE_plot$simed_from_Ycoord == HE_plot$assigned_to_Xcoord),]
# self_assignments_HE$panel = "HE_600"
# self_assignments_HE2 = self_assignments_HE[,c("panel","simulated_from","proportion")]
# 
# self_assignements_summary = rbind.data.frame(self_assignments_FST2,self_assignments_composite2,self_assignments_HE2)
# 
# write.csv(self_assignements_summary, file = "./summary_hundySim_by_POP.csv", row.names = F, quote = F)

```

